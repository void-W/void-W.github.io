---
layout: post
title: "近况以及一些新学到的东西"
date: 2021-01-02
tags: 每周一记
---

## 新工作

去年十一月中旬，我终于有了一份新工作——作为一名程序员入职了红棉小冰公司。虽然这一份工作的体验和我之前的工作大相径庭，但并不是什么坏事。而且你可以从很多地方得到关于各行各业的描述，但是其实只有真正亲身经历了，你才能真正明白那些信息背后的实质。并且，托新工作的福，很早之前就想好好学一学的python以及爬虫终于被强行提上了日程。

## Python爬虫

虽然我应聘的是后端开发的岗位，但是一定要统计一下的话，过去的一个多月里，我花在爬虫工作上的时间甚至要多于真正的后端开发。我觉得爬虫的基本思路还是非常简单的，就是编写程序去发送一些HTTP请求，以获得一些你想要的数据。但是在真正实践的过程中又会有许许多多的问题。

个人认为爬虫的工作主要分两部分：

#### 分析网页

爬虫的本质是用程序替代你去从网上获取信息，但是人类眼里的网页和程序处理的网页是不一样的。当我们浏览网页，我们是靠眼睛来获取信息，但是在对于程序而言这就是一份html文件。所以首先要将视觉上的逻辑转为HTML语法上的逻辑。

最简单的方法当然是直接打开网页开发工具，每个浏览器都有这样的功能，帮你直接从页面内容定位到其对应的的HTML元素。然后你可以观察这个元素的属性，或者是它在文档中的位置。整理出一个可以不偏不倚地找到这个元素的逻辑，方便之后解析网页并抓取数据。

不过也不是所有的网页分析起来都这么一帆风顺，我遇到的比较直接的问题有

1. ##### 由前端完成渲染的内容

   有一些是很明显的，比如不断下拉动态加载的图片。也有一开始就由前端完成渲染的界面。所以有一些是可以直接通过观察来确定的。但更加粗暴的办法可以是直接获取这个页面的源文件，因为源HTML中没有的内容那肯定是之后渲染的。

2. ##### 网页内的frame元素

   这是我在爬取某个网站时已经使用selenium，可是依旧无法定位到我想要的元素所发现的问题。那个元素是在一个frame元素之内。虽然目前依旧不是很懂前端的我还没有彻底理解frame元素，但简单来说就好像网页之内的另一个网页。

总的来说以上的内容都是无法在原始HTML页面内获得的信息。而对应的解决方案主要有两种

1. 使用selenium之类的工具控制真实的浏览器进行渲染，但是这样的操作效率往往低下
2. 不论是什么样的页面形式，浏览器与服务器之间的交互始终是基于HTTP协议的，所以找到对应的HTTP URL去请求，依旧还是可以的到想要的数据。但是这里的接口可能会有参数加密，登陆验证，cookie验证等等一系列问题，处理起来会复杂一些。

#### 模拟请求

分析一通之后，我们需要编写程序来替代手工操作获取信息。在这里会遇到的比较大的问题应该就是如何避免被判定为爬虫了。因为既然有爬虫，各大网站肯定都有一定的反爬虫手段。最基本的绕过反爬的方向有：

1. ##### 伪装自己，不要被发现

   服务器会判定你为爬虫可能是基于很多理由，比如登陆频率，比如你的HTTP请求头不齐全，所以研究对方的逻辑，采取对应的办法。

2. ##### 即便被发现了，研究它的限制机制，想办法继续获取数据

   使用这个方法一般是因为第一条路走不通，又或者是就是希望能够大批量的获取数据，所以不可避免可能会被发现。而网站可能会选择封你的IP或者账号，所以建立一个账号（cookie）池和IP池是常规的解决方案。

当然实际工作中遇到的细节问题肯定不止以上提到的。而且作为更完整的解决方案，应当还要考虑后续的数据处理以及持久化，甚至于需求量巨大时，是否需要建立爬虫集群，构建分布式爬虫系统，这时候可能还要有任务调度的问题。

## 写在最后

第一篇每周一记也算是我自己推着自己写的，虽然早有想法，但是并没有前期整理思路的过程。是单纯地想着今天不写的话，明天要出门，后天又是下周了。所以作为坚持每周一记的起点，不论如何今天就是要写完的。希望日后的我再来看这篇时不要嘲笑哈哈哈。

